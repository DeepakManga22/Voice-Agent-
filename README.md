# ğŸ™ Voice Agent Project â€“ 30 Days of AI Voice Agents

An end-to-end AI-powered conversational voice agent built for the **#30DaysofVoiceAgents** challenge by Murf AI.

The bot listens to your voice, converts it to text (STT), processes it with a Large Language Model (LLM), and responds with Text-to-Speech (TTS) â€” all in real-time.

---

## ğŸš€ Features

- **Speech-to-Text (STT):** Converts audio into text using AssemblyAI.
- **LLM Integration:** Uses Google Gemini API for intelligent, context-aware responses.
- **Text-to-Speech (TTS):** Generates natural-sounding voice replies using Murf API or AssemblyAI.
- **Chat History:** Remembers previous messages in a session for more human-like conversation.
- **Error Handling:** Friendly fallback when APIs fail (e.g., â€œI'm having trouble connecting right nowâ€).
- **Revamped UI:** Clean, minimal interface with an animated record button and automatic audio playback.

---

## ğŸ›  Technologies Used

### Backend

- Python (FastAPI) â€” API server  
- Uvicorn  
- dotenv â€” Manage API keys and configuration

### Frontend

- HTML, CSS, JavaScript  
- Bootstrap â€” Responsive UI styling  
- Fetch API â€” Async communication with backend

### Voice APIs

- Google Gemini  
- AssemblyAI  
- Murf  

---

## ğŸ“‚ Project Structure

Voice-Agent/
â”‚
â”œâ”€â”€ main.py # FastAPI entry point
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .env # API keys (do not share)
â”‚
â”œâ”€â”€ services/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ llm.py # Google Gemini integration
â”‚ â”œâ”€â”€ stt.py # AssemblyAI integration
â”‚ â”œâ”€â”€ tts.py # Murf API integration
â”‚ â””â”€â”€ utils.py # Helper constants & error handling
â”‚
â”œâ”€â”€ static/
â”‚ â””â”€â”€ script.js # UI logic
â”‚
â”œâ”€â”€ templates/
â”‚ â””â”€â”€ index.html # Frontend UI
â”‚
â””â”€â”€ README.md


---

## âš™ï¸ Setup & Installation

### 1ï¸âƒ£ Clone the Repository

git clone https://github.com/your-username/Voice-Agent.git

cd Voice-Agent


### 2ï¸âƒ£ Create a Virtual Environment

python -m venv venv


Activate it:

- **Windows:**
venv\Scripts\activate

- **Mac/Linux:**
source venv/bin/activate


### 3ï¸âƒ£ Install Dependencies

pip install -r requirements.txt

text

### 4ï¸âƒ£ Set Environment Variables

Create a `.env` file in the project root:

GEMINI_API_KEY=your_google_gemini_key

ASSEMBLYAI_API_KEY=your_assemblyai_key

MURF_API_KEY=your_murf_api_key



### 5ï¸âƒ£ Run the Server

uvicorn main:app --reload



Server will be running at: [http://127.0.0.1:8000](http://127.0.0.1:8000)

---

## ğŸŒ API Endpoints

| Method | Endpoint           | Description                            |
|--------|--------------------|------------------------------------|
| POST   | `/llm/query`       | Send text/audio and get AI response |
| POST   | `/stt/transcribe`  | Convert audio to text (AssemblyAI)  |
| POST   | `/tts/speak`       | Convert text to audio (Murf API)    |

---

## ğŸ–¼ï¸ Frontend

Located in:

- `templates/index.html`  
- `static/script.js`  

UI includes:

- ğŸ¤ Record voice  
- ğŸ“ Display transcribed text  
- ğŸ”Š Play AI-generated voice  

---

## ğŸ“Œ Notes

- Keep `.env` private â€” never commit it to GitHub.  
- Make sure all services are active and API keys are valid.  
- This project is for educational purposes â€” API usage may incur costs.

---

Happy building!
